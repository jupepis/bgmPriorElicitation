#' Elicit Edge Inclusion Priors for Variable Pairs Using an LLM
#' that takes into account the remaining variables
#' 
#' 
#' This function uses a large language model (LLM) to evaluate whether conditional
#' associations (edges) exist between variable pairs in a graphical model. It optionally
#' includes study context and considers different orderings of remaining variables in the network
#' to estimate the prior probability of edge inclusion.
#'
#' @param context Optional character string. Describes the research context to inform the LLM's evaluation.
#' @param variable_list A character vector with at least three variable names.
#' @param LLM_model A character string specifying the model to use. One of: `"gpt-4o"`, `"gpt-4-turbo"`,
#'   `"gpt-3.5-turbo"`, `"mixtral"`, or `"llama-3"`.
#' @param max_tokens Integer. The maximum number of tokens the LLM can generate. Maximum depends on the selected model.
#' @param update_key Logical. If `TRUE`, updates the OpenAI API key once. Default is `FALSE`.
#' @param n_perm Optional integer. Number of sampled permutations of remaining variables. Ignored for small sets.
#' If `NULL`, two permutations are generated by default. The maximum is 50.
#' @param seed Integer. Random seed for reproducibility of the permutations. Default is `123`.
#' @param prompt_specs Optional list of user/system prompt overrides. Must contain `user` and `system` strings.
#'
#' @return A list of class `"llmPriorElicit"` containing:
#' \describe{
#'   \item{`relation_df`}{A data frame with columns `var1`, `var2`, and `prob`, containing the estimated
#'     prior probabilities of conditional associations between variable pairs.}
#'   \item{`raw_LLM`}{A data frame of all raw LLM prompt-response data and token probabilities.}
#'   \item{`arguments`}{A list of the function input arguments for reproducibility.}
#' }
#'
#' @details
#' The function examines all unique variable pairs and, for each, prompts the LLM
#' to assess the presence of a conditional association, factoring in remaining variables in different
#' permutations. If context is provided, it is included in the prompt to inform decisions.
#'
#' The returned edge inclusion probability reflects the average over all considered permutations
#' for each variable pair. The function handles both default and user-specified prompting structures.
#'
#' @examples
#' \dontrun{
#' result <- llmPriorElicit(
#'   context = "This study examines the relationship between screen time, physical activity, and cardiovascular health.",
#'   variable_list = c("Screen Time", "Physical Activity", "Cardiovascular Health"),
#'   LLM_model = "gpt-4o"
#' )
#' print(result$relation_df)
#' }
#'
#' @import gtools  # this will make sense when we turn it into a package 
#' @export


llmPriorElicit <- function(context,
                           variable_list,
                           LLM_model = "gpt-4o",
                           max_tokens = 2000,
                           update_key = FALSE,
                           n_perm = NULL,
                           seed = 123,
                           prompt_specs = NULL) {
  # Validate arguments --------------------------------------------------------
  stopifnot("'context' should be a character string or NULL." = is.character(context) | is.null(context))
  stopifnot("'variable_list' should be a vector containing at least 3 variables." = is.vector(variable_list) && length(variable_list) >= 3)
  stopifnot("All entries in 'variable_list' should be character strings." =
              all(sapply(variable_list, is.character)))
  
  
  # Define maximum token limits for each model
  max_token_limits <- list(
    "gpt-4o" = 4096,
    "gpt-4-turbo" = 4096,
    "gpt-3.5-turbo" = 4096,
    "mixtral" = 4096,
    "llama-3" = 2048
  )
  
  # Validate 'max_tokens' based on the selected model -------------------------
  if (!is.null(max_tokens)) {
    max_limit <- max_token_limits[[LLM_model]]
    if (is.null(max_limit)) {
      stop(paste("Unsupported model:", LLM_model))
    }
    if (!is.numeric(max_tokens) || max_tokens <= 0 || max_tokens > max_limit) {
      stop(paste0("For '", LLM_model, "', 'max_tokens' should be a whole number above 0 and not higher than ", max_limit, "."))
    }
  }
  # permutation checks ---------------------------------------------------------
  # if n_perm is missing and there is only 1 variables left, set it to 2
  if (!missing(n_perm) && n_perm > 2 &&  length(variable_list) == 3) {
    message("Ignoring n_perm: Generating 2 repetitions since there is only 1 remaining variable.")
  }
  # for no_variable_list > 4, n_perm must be equal to or smaller than variable_list - 2!
  if (!missing(n_perm) && n_perm > factorial(length(variable_list) - 2) && length(variable_list) <= 6  && length(variable_list) > 3) {
    stop(
      "Requested `n_perm` (", n_perm, ") exceeds the maximum possible permutations (", factorial(length(variable_list) - 2), ") for the provided number of variables. Reduce `n_perm` or set to NULL."
    )
  }
  # if n_perm is zero 
  if (!missing(n_perm) && n_perm == 0) {
    stop("n_perm cannot be zero. Please provide a positive integer up to 50 or set to NULL.")
  }
  # if n_perm is missing set it to 2 
  if (missing(n_perm)) {
    n_perm <- 2 # generate two permutations by default
      message("The n_perm argument was not specified. The function will proceed using two permutations of the remaining variables.")
  }
  # cap the number of possible permutations to 50 
  if (n_perm > 50) {
    stop(
      "Requested `n_perm` (", n_perm, ") exceeds maximum possible permutations which is set to 50. Reduce `n_perm` or set to NULL."
    )
  }
 

# Prompts -------------------------------------------------------------------
  if (!is.null(prompt_specs)) {  # In case the user wants to override the default prompts
    specs <- prompt_specs
    if (length(specs) == 1) specs <- rep(specs, 2)
    
    bern_prompts <- do.call(rbind, lapply(specs, function(spec) {
      data.frame(
        Function            = "bernoulli",
        Function.Part       = "bernoulli",
        context             = if (grepl("\\(context\\)", spec$user)) "y" else "n",
        Variation.Prompt    = "override",
        Variation.Sys.Prompt= "override",
        Prompt              = spec$user,
        Sys.Prompt          = spec$system,
        stringsAsFactors    = FALSE
      )
    }))
  } else {
  # Define the prompts within the function (only second and fourth prompts)
  bern_prompts <- data.frame(
    Function = rep("bernoulli", 2),  
    Function.Part = rep("bernoulli", 2),
    context = c("n", "y"),  
    Variation.Prompt = rep("Prompt1", 2),
    Variation.Sys.Prompt = rep("Prompt1", 2),
    Prompt = c(
      "Establish whether there is a conditional association between the variables x and y. If a conditional association exists, it means that the variables remain related even after accounting for the relationships between the other variables in the network. However, if the other variables explain away the relation between x and y, then an edge should be absent. Your output should be either 'I' for included edges, meaning there is a conditional association between the variables, or 'E' for excluded edges, meaning the association is fully explained by the other variables in the network. \n\nTarget pair: '(pairs_df[i, 2])' & '(pairs_df[i, 1])' Consider the following remaining variables in the network when evaluating the presence of a relation in the target pair: (remaining_vars). \n\nExample output:\n'Exercise Frequency' & 'Heart Disease': I\n'Exercise Frequency' & 'Screen Time': E\n'Screen Time' & 'Heart Disease': I",
      
      "Establish whether there is a conditional association between the variables x and y. If a conditional association exists, it means that the variables remain related even after accounting for the relationships between the other variables in the network. However, if the other variables explain away the relation between x and y, then an edge should be absent. Your output should be either 'I' for included edges, meaning there is a conditional association between the variables, or 'E' for excluded edges, meaning the association is fully explained by the other variables in the network. \n\nTarget pair: '(pairs_df[i, 2])' & '(pairs_df[i, 1])' Consider the following remaining variables in the network when evaluating the presence of a relation in the target pair: (remaining_vars). \n\nExample output:\n'Exercise Frequency' & 'Heart Disease': I\n'Exercise Frequency' & 'Screen Time': E\n'Screen Time' & 'Heart Disease': I \nTake into account the following context when deciding the type of relationship: '(context)'."
    ),
    Sys.Prompt = rep("You are an expert in using graphical models to study psychological constructs. You will be asked to classify whether there is a conditional relationship between pairs of variables in a Markov random field graphical model, applied to psychological research. You must use your vast prior knowledge of the relationships between the variables to make informed decisions. When presented with two variable names, you should evaluate whether or not there is an edge between those two variables in the graphical model (which reflects a conditional association) between them after taking into account the remaining variables. If there is a conditional association between two variables, then the edge should be categorized as included (by outputting 'I'). If there is no conditional association, then the edge should be categorized as excluded (by outputting 'E'). Therefore, output should be either 'I' or 'E'! Do not include any additional explanation or other text. Since you must make decisions about conditional associations, be sure to consider the remaining variables when making your decision.", 2)
  )
  }
  # Create objects for tryCatch output
  raw_LLM <- NULL
  raw_LLM_prompt <- NULL
  logprobs_LLM <- NULL
  logprobs_LLM_prompt <- NULL
  prob_relation_df <- NULL
  
  # Generate all unique combinations
  pairs_df <- data.frame(var1 = character(), var2 = character())
  for(i in 1:(length(variable_list)-1)) {
    for(j in (i+1):length(variable_list)) {
      pairs_df <- rbind(pairs_df, data.frame(var1 = variable_list[[i]], var2 = variable_list[[j]]))
    }
  }
  
  n_pairs <- nrow(pairs_df)
  raw_LLM <- list()
  logprobs_LLM <- list()
  set.seed(seed) # For reproducibility
  # Main evaluation loop
  for (i in 1:n_pairs) {
    var1 <- pairs_df[i, 1]
    var2 <- pairs_df[i, 2]
    remaining_vars <- setdiff(variable_list, c(var1, var2))
    
    # Generate permutations of remaining variables
      # For length > 2, respect the specified n_perm 
      if (length(remaining_vars) >= 2) {
        perms <- matrix(nrow = 0, ncol = length(remaining_vars))
        while (nrow(perms) < n_perm) {
          new_perm <- sample(remaining_vars, length(remaining_vars), replace = FALSE)
          if (!any(apply(perms, 1, function(x) all(x == new_perm)))) {
            perms <- rbind(perms, new_perm)
          }
        }
        remaining_vars_list <- lapply(1:n_perm, function(p) perms[p, ])
      } 
    # 
    else if (length(remaining_vars) == 1 && n_perm == 1){
      # If only one remaining variable, and n_perm is 1 
      remaining_vars_list <- list(remaining_vars)
    }

    else {     # Otherwise just repeat the single variable twice 
      remaining_vars_list <- list(remaining_vars, remaining_vars)  # Repeat twice
    }
    
    print(paste0("Processing pair ", i, "/", n_pairs, ": ", var1, " - ", var2))
    
    # Evaluate pair for each ordering of remaining vars
    for (g in 1:length(remaining_vars_list)) {
      remaining_vars_str <- paste(remaining_vars_list[[g]], collapse = ", ")
      
      # Select and format prompt
      # In the prompt generation section, change to:
      if (is.null(context)) {
        prompt <- gsub("\\(pairs_df\\[i, 1\\]\\)", var1,
                       gsub("\\(pairs_df\\[i, 2\\]\\)", var2,
                            gsub("\\(remaining_vars\\)", remaining_vars_str,
                                 bern_prompts$Prompt[1])))
      } else {
        prompt <- gsub("\\(pairs_df\\[i, 1\\]\\)", var1,
                       gsub("\\(pairs_df\\[i, 2\\]\\)", var2,
                            gsub("\\(context\\)", context,
                                 gsub("\\(remaining_vars\\)", remaining_vars_str,
                                      bern_prompts$Prompt[2]))))
      }
      system_prompt <- bern_prompts$Sys.Prompt[1]
      
      # LLM
      LLM_output <- LLM(prompt = prompt,
                        LLM_model = LLM_model,
                        max_tokens = max_tokens,
                        temperature = 0,
                        logprobs = TRUE,
                        raw_output = TRUE,
                        system_prompt = system_prompt,
                        update_key = update_key)
      
      update_key <- FALSE # make sure api key is only updated once
      raw_LLM_prompt[[g]] <- c(prompt = prompt, system_prompt = system_prompt, LLM_output$raw_content)
      logprobs_LLM_prompt[[g]] <- LLM_output$top5_tokens
    }
    
    raw_LLM[[i]] <- raw_LLM_prompt
    logprobs_LLM[[i]] <- logprobs_LLM_prompt
  }
  
  
  #tryCatch in case processing steps fail the raw output will still be outputted
  tryCatch({
    
    if (LLM_model == "mixtral" | LLM_model == "llama-3"){
      last_token <- NULL
      for (i in 1:n_pairs) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM[[i]])){
          last_token_t[[j]] <- logprobs_LLM[[i]][[j]][[1]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token[[i]] <- last_token_t
      }
      
    } else {
      last_token <- NULL
      for (i in 1:n_pairs) {
        last_token_t <- NULL
        for (j in 1:length(logprobs_LLM[[i]])){
          last_token_t[[j]] <- logprobs_LLM[[i]][[j]][[length(logprobs_LLM[[i]][[j]])]]
          last_token_t[[j]]$top5_tokens <- trimws(tolower(last_token_t[[j]]$top5_tokens))
        }
        last_token[[i]] <- last_token_t
      }
      
    }
    
    all_prob <- list()
    valid_tokens <- c("i", "e")
    
    for (l in 1:length(last_token)) {
      probs <- list()
      for (g in 1:length(last_token[[l]])) {
        # Initialize storage for this prompt
        token_probs <- data.frame(
          Class = character(),
          Probability = numeric(),
          stringsAsFactors = FALSE
        )
        
        # Extract probabilities for "I" and "E"
        for (m in 1:nrow(last_token[[l]][[g]])) {
          token <- trimws(tolower(last_token[[l]][[g]]$top5_tokens[m]))
          if (token %in% valid_tokens) {
            token_probs <- rbind(
              token_probs,
              data.frame(
                Class = token,
                Probability = as.numeric(last_token[[l]][[g]]$probability[m]),
                stringsAsFactors = FALSE
              )
            )
          }
        }
        
        # If no valid tokens, default to missing
        if (nrow(token_probs) == 0) {
          token_probs <- data.frame(
            Class = "-",
            Probability = NA_real_,
            stringsAsFactors = FALSE
          )
        }
        
        probs[[g]] <- token_probs
      }
      all_prob[[l]] <- probs
    }
    
    c_class <- NULL
    for (i in 1:n_pairs) {
      # Determine how many prompts were used (1 if no context, 2 if context provided)
      n_prompts <- length(all_prob[[i]]) # this should fix  the issue with n_perm = 1 and context provided 
      prob_i <- 0
      prob_e <- 0
      
      for (k in 1:n_prompts) {  # Only loop through used prompts
        for (j in seq_along(all_prob[[i]][[k]]$Class)) {
          token <- trimws(tolower(all_prob[[i]][[k]]$Class[j]))
          if (token == "i") {
            prob_i <- prob_i + as.numeric(all_prob[[i]][[k]]$Probability[j])
          } else if (token == "e") {
            prob_e <- prob_e + as.numeric(all_prob[[i]][[k]]$Probability[j])
          }
        }
      }
      
      # Normalize to get P("I" | "I" or "E")
      if (prob_i + prob_e > 0) {
        c_class[i] <- round(prob_i / (prob_i + prob_e), 2)
      } else {
        c_class[i] <- 0.5  # Default if no valid tokens
      }
    }
    
    # Handle NAs (shouldn't occur with new logic, but kept for safety)
    c_class[is.na(c_class)] <- 0.5
    
    prob_relation_df <- data.frame(
      var1 = pairs_df[, 1], 
      var2 = pairs_df[, 2], 
      prob = c_class, 
      row.names = NULL
    )
    
  }, error = function(e) {
    cat(paste0("Warning: Unable to process LLM output -> ", e$message, "."),
        "Only part of the output is returned.", sep = "\n")
  })
  
  # Initialize the output list
  output <- list()
  
  # Add raw_LLM to output
  
  tryCatch({
    # Initialize empty dataframe
    flattened_df_raw_LLM <- data.frame(
      relationship = integer(),
      iteration = integer(),
      LLM_model = character(),
      prompt = character(),
      system_prompt = character(),
      content = character(),
      finish_reason = character(),
      prompt_tokens = numeric(),
      answer_tokens = numeric(),
      total_tokens = numeric(),
      error = character(),
      first_token = character(),       # New: First token (e.g., "I" or "E")
      first_token_prob = numeric(),    # New: Probability of first token
      stringsAsFactors = FALSE
    )
    
    # Flatten raw_LLM and add first token info
    for (i in seq_along(raw_LLM)) {
      for (j in seq_along(raw_LLM[[i]])) {
        temp <- raw_LLM[[i]][[j]]
        
        # Extract first token and its probability
        first_token_info <- if (!is.null(logprobs_LLM[[i]][[j]]) && length(logprobs_LLM[[i]][[j]]) > 0) {
          first_token_data <- logprobs_LLM[[i]][[j]][[1]]  # First token's data
          data.frame(
            first_token = trimws(tolower(first_token_data$top5_tokens[1])),
            first_token_prob = as.numeric(first_token_data$probability[1]),
            stringsAsFactors = FALSE
          )
        } else {
          data.frame(
            first_token = NA_character_,
            first_token_prob = NA_real_,
            stringsAsFactors = FALSE
          )
        }
        
        flattened_df_raw_LLM <- rbind(
          flattened_df_raw_LLM,
          data.frame(
            relationship = i,
            iteration = j,
            LLM_model = temp$LLM_model,
            prompt = temp$prompt,
            system_prompt = temp$system_prompt,
            content = temp$content,
            finish_reason = temp$finish_reason,
            prompt_tokens = temp$prompt_tokens,
            answer_tokens = temp$answer_tokens,
            total_tokens = temp$total_tokens,
            error = ifelse(is.null(temp$error), NA, temp$error),
            first_token = first_token_info$first_token,
            first_token_prob = first_token_info$first_token_prob,
            stringsAsFactors = FALSE
          )
        )
      }
    }
    output$raw_LLM <- flattened_df_raw_LLM
  }, error = function(e) {
    cat(paste0("Warning: Unable to return raw LLM output -> ", e$message, "."),
        "Only part of the output is returned.", sep = "\n")
  })
  
  
  # Adding prob_relation_df to output
  output$relation_df <- prob_relation_df
  
  
  print(paste0("Total of LLM prompts: ", n_pairs * 2))
  
  # save the arguments in the output
  output$arguments <- list(
    context = context,
    variable_list = variable_list,
    LLM_model = LLM_model,
    max_tokens = max_tokens,
    update_key = update_key,
    n_perm = n_perm,
    seed = seed
  )
  
  # give openai error if there is no output at all
  if (length(output) == 0) {
    for (i in 1:n_pairs) {
      if (!is.null(raw_LLM[[i]][[1]]$error$message)) {
        stop(raw_LLM[[i]][[1]]$error$message)
      } else if (!is.null(raw_LLM[[i]][[2]]$error$message)) {
        stop(raw_LLM[[i]][[2]]$error$message)
      }
    }
  }
  class(output) <- "llmPriorElicit"
  return(output)
}

